{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2cfe715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chromosome 1: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.1.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.1.gff3\n",
      "Processing Chromosome 10: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.10.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.10.gff3\n",
      "Processing Chromosome 2: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.2.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.2.gff3\n",
      "Processing Chromosome 3: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.3.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.3.gff3\n",
      "Processing Chromosome 4: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.4.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.4.gff3\n",
      "Processing Chromosome 5: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.5.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.5.gff3\n",
      "Processing Chromosome 6: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.6.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.6.gff3\n",
      "Processing Chromosome 7: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.7.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.7.gff3\n",
      "Processing Chromosome 8: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.8.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.8.gff3\n",
      "Processing Chromosome 9: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.dna.chromosome.9.fa.gz & Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.9.gff3\n",
      "\n",
      "Extracted Gene Sequences:\n",
      "                 gene_id chromosome chromosome_id   start     end strand  \\\n",
      "0  gene:Zm00001eb000010          1             1   34616   40204      +   \n",
      "1  gene:Zm00001eb000020          1             1   41213   46762      -   \n",
      "2  gene:Zm00001eb000030          1             1  106147  106620      -   \n",
      "3  gene:Zm00001eb000040          1             1  107079  108196      -   \n",
      "4  gene:Zm00001eb000050          1             1  108553  114382      -   \n",
      "\n",
      "                                            sequence  \n",
      "0  TCTCACGCCAATATGCCATGGATAATGCACGCGGGAACGGAACAAA...  \n",
      "1  TCTCAGGTTTGAAACAAGCCACAGCTTAATTTCCATACAGTCACTG...  \n",
      "2  TATTTCCCCACACTGAATGCCTTTGTCTTTTACGTGGCTCGTATTT...  \n",
      "3  AAATTTAAATTCCTAATTGTTATACCTACATGTCCCTACAATACAA...  \n",
      "4  CTGCCGAGCAGTGGAGAAGGACCGGCGTCCGGAGGTGGCCGGCGGC...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# Directories\n",
    "dna_dir = \"data/dna_sequences/\"\n",
    "gff3_dir = \"data/gff3_files/\"\n",
    "\n",
    "# Helper: extract chromosome ID from filename\n",
    "def extract_chr_id(filename):\n",
    "    # Works for names like: Zea_mays.Zm-B73-REFERENCE-NAM-5.0.60.chromosome.1.gff3\n",
    "    parts = filename.split(\"chromosome.\")\n",
    "    return parts[1].split(\".\")[0] if len(parts) > 1 else None\n",
    "\n",
    "# Collect and sort all relevant files\n",
    "fasta_files = sorted([\n",
    "    os.path.join(dna_dir, f) for f in os.listdir(dna_dir)\n",
    "    if f.lower().endswith(\".fa.gz\") or f.lower().endswith(\".fasta\")\n",
    "])\n",
    "gff3_files = sorted([\n",
    "    os.path.join(gff3_dir, f) for f in os.listdir(gff3_dir)\n",
    "    if f.lower().endswith(\".gff3\")\n",
    "])\n",
    "\n",
    "# Create a mapping: chromosome_id -> file path\n",
    "fasta_map = {extract_chr_id(os.path.basename(f)): f for f in fasta_files}\n",
    "gff3_map = {extract_chr_id(os.path.basename(f)): f for f in gff3_files}\n",
    "\n",
    "# Function to parse GFF3 and extract gene features\n",
    "def parse_gff3(gff3_file):\n",
    "    genes = []\n",
    "    with open(gff3_file, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) < 9:\n",
    "                continue\n",
    "            if parts[2] == \"gene\":\n",
    "                start = int(parts[3]) - 1  # Convert from 1-based to 0-based\n",
    "                end = int(parts[4])\n",
    "                strand = parts[6]\n",
    "                attr = parts[8]\n",
    "                gene_id = \"NA\"\n",
    "                for field in attr.split(\";\"):\n",
    "                    if field.startswith(\"ID=\"):\n",
    "                        gene_id = field.split(\"=\")[1]\n",
    "                        break\n",
    "                genes.append((start, end, strand, gene_id))\n",
    "    return genes\n",
    "\n",
    "# List to collect all extracted gene data\n",
    "gene_sequences = []\n",
    "\n",
    "# Match and process chromosome-wise\n",
    "for chr_id in sorted(set(fasta_map.keys()) & set(gff3_map.keys())):\n",
    "    fasta_path = fasta_map[chr_id]\n",
    "    gff_path = gff3_map[chr_id]\n",
    "    \n",
    "    print(f\"Processing Chromosome {chr_id}: {os.path.basename(fasta_path)} & {os.path.basename(gff_path)}\")\n",
    "\n",
    "    # Read DNA sequence (gz or regular)\n",
    "    if fasta_path.endswith(\".gz\"):\n",
    "        with gzip.open(fasta_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "            record = next(SeqIO.parse(f, \"fasta\"))\n",
    "    else:\n",
    "        with open(fasta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            record = next(SeqIO.parse(f, \"fasta\"))\n",
    "\n",
    "    chrom_seq = record.seq\n",
    "    chrom_name = record.id\n",
    "\n",
    "    # Parse GFF3 gene entries\n",
    "    genes = parse_gff3(gff_path)\n",
    "\n",
    "    # Extract and store gene sequences\n",
    "    for start, end, strand, gene_id in genes:\n",
    "        gene_seq = chrom_seq[start:end]\n",
    "        if strand == \"-\":\n",
    "            gene_seq = gene_seq.reverse_complement()\n",
    "        gene_sequences.append({\n",
    "            \"gene_id\": gene_id,\n",
    "            \"chromosome\": chrom_name,\n",
    "            \"chromosome_id\": chr_id,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"strand\": strand,\n",
    "            \"sequence\": str(gene_seq)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_genes = pd.DataFrame(gene_sequences)\n",
    "\n",
    "# Preview the result\n",
    "print(\"\\nExtracted Gene Sequences:\\n\", df_genes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3240a31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSS Window Regions:\n",
      "                 gene_id chromosome chromosome_id   start     end strand  \\\n",
      "0  gene:Zm00001eb000010          1             1   24616   44616      +   \n",
      "1  gene:Zm00001eb000020          1             1   36762   56762      -   \n",
      "2  gene:Zm00001eb000030          1             1   96620  116620      -   \n",
      "3  gene:Zm00001eb000040          1             1   98196  118196      -   \n",
      "4  gene:Zm00001eb000050          1             1  104382  124382      -   \n",
      "\n",
      "      tss  \n",
      "0   34616  \n",
      "1   46762  \n",
      "2  106620  \n",
      "3  108196  \n",
      "4  114382  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the window size around TSS (e.g., 10,000 bp on either side)\n",
    "WINDOW_SIZE = 10000\n",
    "\n",
    "# Calculate TSS and window region\n",
    "def compute_tss_window(df_genes):\n",
    "    windows = []\n",
    "    for _, row in df_genes.iterrows():\n",
    "        if row[\"strand\"] == \"+\":\n",
    "            tss = row[\"start\"]\n",
    "        else:\n",
    "            tss = row[\"end\"]\n",
    "        window_start = max(0, tss - WINDOW_SIZE)\n",
    "        window_end = tss + WINDOW_SIZE\n",
    "        windows.append({\n",
    "            \"gene_id\": row[\"gene_id\"],\n",
    "            \"chromosome\": row[\"chromosome\"],\n",
    "            \"chromosome_id\": row[\"chromosome_id\"],\n",
    "            \"start\": window_start,\n",
    "            \"end\": window_end,\n",
    "            \"strand\": row[\"strand\"],\n",
    "            \"tss\": tss\n",
    "        })\n",
    "    return pd.DataFrame(windows)\n",
    "\n",
    "# Apply it to your extracted gene sequences\n",
    "df_windows = compute_tss_window(df_genes)\n",
    "\n",
    "# Preview the windowed TSS region data\n",
    "print(\"\\nTSS Window Regions:\\n\", df_windows.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39f7c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed-length sequences extracted:\n",
      "                 gene_id chromosome     tss  \\\n",
      "0  gene:Zm00001eb000010          1   34616   \n",
      "1  gene:Zm00001eb000020          1   46762   \n",
      "2  gene:Zm00001eb000030          1  106620   \n",
      "3  gene:Zm00001eb000040          1  108196   \n",
      "4  gene:Zm00001eb000050          1  114382   \n",
      "\n",
      "                                            sequence  \n",
      "0  GTTTATTCGTTCGTTCGTCCGATCGTTCGATCGTTCATGGTTCGTT...  \n",
      "1  CAATTATGTCATATGGGGTATAACTGTCTATTTACAAATGTAGATG...  \n",
      "2  GGGTCGACGGGGCCGCGCGTGGCGCAGGCAGGATCGCCGGGGCCGC...  \n",
      "3  GAGCGAGAGACGACGGGCTGCCTCTTGGCGGCCCAAGAGACGAGGT...  \n",
      "4  TAGTGTTTGACACCCAAGGGGGGGGCTTGGTGCTGGCATGTTGTAG...  \n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store chromosome sequences\n",
    "fasta_sequences = {}\n",
    "\n",
    "# Load each fasta file and map its sequence by chromosome ID\n",
    "for fasta_path in fasta_files:\n",
    "    chrom_id = os.path.basename(fasta_path).split(\"chromosome.\")[1].split(\".\")[0]\n",
    "    if fasta_path.endswith(\".gz\"):\n",
    "        with gzip.open(fasta_path, \"rt\") as handle:\n",
    "            record = next(SeqIO.parse(handle, \"fasta\"))\n",
    "    else:\n",
    "        with open(fasta_path, \"r\") as handle:\n",
    "            record = next(SeqIO.parse(handle, \"fasta\"))\n",
    "    fasta_sequences[chrom_id] = record.seq\n",
    "\n",
    "# Set window size (±10,000 bp = total 20,000)\n",
    "WINDOW_SIZE = 10000\n",
    "FIXED_LENGTH = 2 * WINDOW_SIZE\n",
    "\n",
    "# Extract fixed-length TSS-centered sequences\n",
    "def extract_window_sequence(row):\n",
    "    chrom_id = str(row[\"chromosome_id\"])\n",
    "    chrom_seq = fasta_sequences.get(chrom_id, \"\")\n",
    "\n",
    "    # Clip if chromosome not found\n",
    "    if not chrom_seq:\n",
    "        return \"A\" * FIXED_LENGTH\n",
    "\n",
    "    start = row[\"start\"]\n",
    "    end = row[\"end\"]\n",
    "\n",
    "    # Extract the sequence window\n",
    "    seq = chrom_seq[start:end]\n",
    "    \n",
    "    # Reverse complement if strand is negative\n",
    "    if row[\"strand\"] == \"-\":\n",
    "        seq = seq.reverse_complement()\n",
    "    \n",
    "    # Pad or trim to exactly 20,000 bp\n",
    "    if len(seq) < FIXED_LENGTH:\n",
    "        seq += \"A\" * (FIXED_LENGTH - len(seq))  # pad with A\n",
    "    elif len(seq) > FIXED_LENGTH:\n",
    "        seq = seq[:FIXED_LENGTH]  # truncate\n",
    "\n",
    "    return str(seq)\n",
    "\n",
    "# Apply the function to the df_windows DataFrame\n",
    "df_windows[\"sequence\"] = df_windows.apply(extract_window_sequence, axis=1)\n",
    "\n",
    "# Preview\n",
    "print(\"\\nFixed-length sequences extracted:\\n\", df_windows[[\"gene_id\", \"chromosome\", \"tss\", \"sequence\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4af960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windows.to_csv(\"tss_sequences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42578907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_windows[\"sequence\"].iloc[30])  # Check length of the first sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd354d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Memory-efficient data saved to 'processed_data.npz'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reuse your label encoder\n",
    "def label_encode(sequence):\n",
    "    mapping = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "    encoded = [mapping.get(base, 0) for base in sequence.upper()[:20000]]\n",
    "    if len(encoded) < 20000:\n",
    "        encoded += [0] * (20000 - len(encoded))  # pad if needed\n",
    "    return encoded\n",
    "\n",
    "# Load the DataFrame with sequences (already has 'sequence' column)\n",
    "# Assuming you already have df_windows in memory\n",
    "# If needed: df_windows = pd.read_csv(\"tss_sequences.csv\")\n",
    "\n",
    "# Prepare arrays\n",
    "num_samples = len(df_windows)\n",
    "X = np.zeros((num_samples, 20000), dtype=np.uint8)\n",
    "gene_ids = []\n",
    "chromosomes = []\n",
    "tss_list = []\n",
    "\n",
    "# Stream label encoding\n",
    "for i, row in df_windows.iterrows():\n",
    "    encoded = label_encode(row[\"sequence\"])\n",
    "    X[i] = encoded\n",
    "    gene_ids.append(row[\"gene_id\"])\n",
    "    chromosomes.append(row[\"chromosome\"])\n",
    "    tss_list.append(row[\"tss\"])\n",
    "\n",
    "# Convert metadata to arrays\n",
    "gene_ids = np.array(gene_ids)\n",
    "chromosomes = np.array(chromosomes)\n",
    "tss_list = np.array(tss_list)\n",
    "\n",
    "# Save all in compressed format\n",
    "np.savez_compressed(\"processed_data.npz\", X=X, gene_id=gene_ids, chromosome=chromosomes, tss=tss_list)\n",
    "\n",
    "print(\"✅ Memory-efficient data saved to 'processed_data.npz'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windows1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c22ce6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['start', 'end']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m tss_list \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 2. Load df_genes with gene_id → start/end (from original CSV)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Required for computing Y\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df_meta \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessed_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgene_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m df_genes \u001b[38;5;241m=\u001b[39m df_meta\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 3. Create gene_id → (start, end) mapping\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:140\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(usecols)\u001b[38;5;241m.\u001b[39missubset(\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names\n\u001b[0;32m    139\u001b[0m ):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_usecols_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(usecols):  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:979\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[1;34m(self, usecols, names)\u001b[0m\n\u001b[0;32m    977\u001b[0m missing \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m usecols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    981\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    982\u001b[0m     )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m usecols\n",
      "\u001b[1;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['start', 'end']"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load from .npz file (created earlier)\n",
    "data = np.load(\"processed_data.npz\", allow_pickle=True)\n",
    "X = data[\"X\"]\n",
    "gene_ids = data[\"gene_id\"]\n",
    "chromosomes = data[\"chromosome\"]\n",
    "tss_list = data[\"tss\"]\n",
    "\n",
    "# 2. Load df_genes with gene_id → start/end (from original CSV)\n",
    "# Required for computing Y\n",
    "df_meta = pd.read_csv(\"processed_data.csv\", usecols=[\"gene_id\", \"start\", \"end\"])\n",
    "df_genes = df_meta.drop_duplicates(subset=\"gene_id\")\n",
    "\n",
    "# 3. Create gene_id → (start, end) mapping\n",
    "gene_dict = {\n",
    "    row[\"gene_id\"]: (row[\"start\"], row[\"end\"])\n",
    "    for _, row in df_genes.iterrows()\n",
    "}\n",
    "\n",
    "# 4. Generate Y\n",
    "def generate_labels_for_window(window_start, gene_start, gene_end):\n",
    "    labels = np.zeros(20000, dtype=int)\n",
    "    gene_relative_start = max(0, gene_start - window_start)\n",
    "    gene_relative_end = min(20000, gene_end - window_start)\n",
    "    if gene_relative_start < gene_relative_end:\n",
    "        labels[gene_relative_start:gene_relative_end] = 1\n",
    "    return labels\n",
    "\n",
    "Y = []\n",
    "df_windows = pd.read_csv(\"processed_data.csv\", usecols=[\"gene_id\", \"start\"])\n",
    "for i, row in df_windows.iterrows():\n",
    "    gene_id = row[\"gene_id\"]\n",
    "    window_start = row[\"start\"]\n",
    "    if gene_id in gene_dict:\n",
    "        gene_start, gene_end = gene_dict[gene_id]\n",
    "        label = generate_labels_for_window(window_start, gene_start, gene_end)\n",
    "    else:\n",
    "        label = np.zeros(20000, dtype=int)\n",
    "    Y.append(label)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# 5. Split X and Y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"✅ Data loaded, labeled, and split.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10454794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_windows[[f\"base_{i}\" for i in range(20000)]].values.astype(np.int32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
